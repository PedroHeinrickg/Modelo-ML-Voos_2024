{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "948bed33",
      "metadata": {
        "id": "948bed33"
      },
      "source": [
        "### 1 - PREPARA√á√ÉO E CARREGAMENTO DOS DADOS ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6214b02a",
      "metadata": {
        "id": "6214b02a"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75fe23ec",
      "metadata": {
        "id": "75fe23ec"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    df = pd.read_csv(\"flight_data_2024.csv\")\n",
        "    print(\"Arquivo carregado com sucesso!\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"ERRO: Arquivo n√£o encontrado\")\n",
        "\n",
        "print(f\"Dataset carregado com {df.shape[0]} linhas e {df.shape[1]} colunas.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6773534",
      "metadata": {
        "id": "d6773534"
      },
      "source": [
        "### 2 - INSPE√á√ÉO E QUALIDADE DOS DADOS ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79d1cd14",
      "metadata": {
        "id": "79d1cd14"
      },
      "outputs": [],
      "source": [
        "print(\"\\n --- 2.1. Primeiras linhas ---\")\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cdc7a2b",
      "metadata": {
        "id": "7cdc7a2b"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    df['flight_id'] = np.arange(df.shape[0]) + 1\n",
        "    colunas = ['flight_id'] + [col for col in df.columns if col != 'flight_id']\n",
        "    df = df[colunas]\n",
        "\n",
        "    print(f\"\\n Coluna 'flight_id' criada com sucesso!\")\n",
        "    print(f\"Total de {df.shape[0]:,} voos.\")\n",
        "\n",
        "    print(\"\\n ---- 5 primeiras linhas do df com o ID novo ----\")\n",
        "    print(df[['flight_id', 'fl_date', 'origin', 'cancelled']].head(5))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ocorreu um erro inesperado: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b984060",
      "metadata": {
        "id": "0b984060"
      },
      "outputs": [],
      "source": [
        "print(f\"--- Descri√ß√£o dos dados ---\")\n",
        "display(df.describe().T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce317779",
      "metadata": {
        "id": "ce317779"
      },
      "outputs": [],
      "source": [
        "print(\"\\n --- 2.3. Contagem de valores nulos ---\")\n",
        "nulos = df.isnull().sum().sort_values(ascending=False)\n",
        "nulos_percentual = (df.isnull().sum() / len(df) * 100).sort_values(ascending=False)\n",
        "df_nulos = pd.DataFrame({'Nulos': nulos, 'Percentual': nulos_percentual})\n",
        "print(df_nulos[df_nulos['Nulos'] > 0]) # Exibe apenas colunas com nulos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cb4699a",
      "metadata": {
        "id": "1cb4699a"
      },
      "outputs": [],
      "source": [
        "voos_cancelados = df[df['cancelled'] == 1].copy()\n",
        "cidades_distintas = voos_cancelados['origin_city_name'].dropna().unique().tolist()\n",
        "total_cidades = len(cidades_distintas)\n",
        "total_cancelamentos = voos_cancelados['cancelled'].sum()\n",
        "\n",
        "print(f'O total de cidades de origem distinctas: {total_cidades}')\n",
        "print(f'O total de Voos cancelados √©: {total_cancelamentos}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75a85a59",
      "metadata": {
        "id": "75a85a59"
      },
      "outputs": [],
      "source": [
        "# 2. Contagem das Observa√ß√µes por M√™s\n",
        "    # value_counts() conta a frequ√™ncia e sort_index() garante a ordem correta dos meses (1, 2, 3...)\n",
        "contagem_mensal = df['month'].value_counts().sort_index()\n",
        "\n",
        "# 3. Cria√ß√£o do Gr√°fico de Barras\n",
        "ax = sns.barplot(x=contagem_mensal.index, y=contagem_mensal.values, palette=\"viridis\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a40e722",
      "metadata": {
        "id": "5a40e722"
      },
      "outputs": [],
      "source": [
        "cancelamentos_por_cidade = (\n",
        "    df.groupby('origin_city_name')['cancelled'].sum().sort_values(ascending=False)\n",
        ")\n",
        "\n",
        "cidades_com_mais_cancelamentos = cancelamentos_por_cidade.head(15)\n",
        "print(f\"\\n --- Gerando Gr√°fico: TOP 15 cidades por n√∫mero de cancelamentos ---\")\n",
        "\n",
        "#mplt.figure(figsize=(14, 7))\n",
        "plt.figure(figsize=(14,7))\n",
        "grafico_voos_cancelados = sns.barplot(\n",
        "    x=cidades_com_mais_cancelamentos.index,\n",
        "    y=cidades_com_mais_cancelamentos.values,\n",
        "    palette=\"Reds_d\"\n",
        ")\n",
        "\n",
        "# Adicionando T√≠tulos e R√≥tulos\n",
        "plt.title('Top 15 Cidades de Origem com Maior N√∫mero de Voos Cancelados', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Cidade de Origem', fontsize=12)\n",
        "plt.ylabel('Total de Voos Cancelados', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "    # Linhas que faltam para finalizar: Adicionar anota√ß√µes e exibir\n",
        "\n",
        "    # 1. Adicionar os valores exatos em cima de cada barra (como fizemos antes)\n",
        "for p in grafico_voos_cancelados.patches:\n",
        "        grafico_voos_cancelados.annotate(f'{int(p.get_height()):,}',\n",
        "                    (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                    ha = 'center', va = 'center',\n",
        "                    xytext = (0, 9),\n",
        "                    textcoords = 'offset points')\n",
        "\n",
        "    # 2. Ajustar o layout\n",
        "plt.tight_layout()\n",
        "\n",
        "    # 3. Exibir o gr√°fico!\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbf2d5a9",
      "metadata": {
        "id": "fbf2d5a9"
      },
      "outputs": [],
      "source": [
        "df['total_minutos_atraso'] = df['weather_delay'] + df['late_aircraft_delay']\n",
        "df['flag_atrasado'] = (df['total_minutos_atraso'] > 15).astype(int)\n",
        "total_voos_atrasados = df['flag_atrasado'].sum()\n",
        "print(f\"O total de Voos atrasados √©: {total_voos_atrasados}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "703d6cea",
      "metadata": {
        "id": "703d6cea"
      },
      "outputs": [],
      "source": [
        "atrasos_por_cidade = (\n",
        "    df.groupby('origin_city_name')['flag_atrasado'].sum().sort_values(ascending=False)\n",
        "    )\n",
        "\n",
        "cidades_com_mais_atrasos = atrasos_por_cidade.head(15)\n",
        "print(f\"\\n Gerando gr√°fico das TOP 15 cidades com mais atrasos\")\n",
        "\n",
        "plt.figure(figsize=(14, 7))\n",
        "grafico_voos_atrasados = sns.barplot(\n",
        "    x=cidades_com_mais_atrasos.index,\n",
        "    y=cidades_com_mais_atrasos.values,\n",
        "    palette=\"Reds_d\"\n",
        ")\n",
        "\n",
        "# Adicionando T√≠tulos e R√≥tulos\n",
        "plt.title('Top 15 Cidades de Origem com Maior N√∫mero de Voos Atrasados', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Cidade de Origem', fontsize=12)\n",
        "plt.ylabel('Total de Voos Atrasados', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "    # Linhas que faltam para finalizar: Adicionar anota√ß√µes e exibir\n",
        "\n",
        "    # 1. Adicionar os valores exatos em cima de cada barra (como fizemos antes)\n",
        "for p in grafico_voos_atrasados.patches:\n",
        "        grafico_voos_atrasados.annotate(f'{int(p.get_height()):,}',\n",
        "                    (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                    ha = 'center', va = 'center',\n",
        "                    xytext = (0, 9),\n",
        "                    textcoords = 'offset points')\n",
        "\n",
        "    # 2. Ajustar o layout\n",
        "plt.tight_layout()\n",
        "\n",
        "    # 3. Exibir o gr√°fico!\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8c3c1db",
      "metadata": {
        "id": "a8c3c1db"
      },
      "outputs": [],
      "source": [
        "# Agrupa pela cidade e aplica as fun√ß√µes de agrega√ß√£o necess√°rias\n",
        "df_resumo_cidade = df.groupby('origin_city_name').agg(\n",
        "        # 1. Quantidade de Voos Agendados (simplesmente a contagem de observa√ß√µes)\n",
        "        quantidade_voos_agendados=('year', 'count'),\n",
        "\n",
        "        # 2. Quantidade de Voos Atrasados (soma do nosso indicador bin√°rio)\n",
        "        quantidade_voos_atrasados=('flag_atrasado', 'sum'),\n",
        "\n",
        "        # 4. Quantidade de Voos Cancelados (soma da coluna 'cancelled')\n",
        "        quantidade_voos_cancelados=('cancelled', 'sum')\n",
        "\n",
        "    ).reset_index() # Transforma o √≠ndice 'origin_city_name' em uma coluna\n",
        "\n",
        "df_resumo_cidade['prop_atrasados'] = (\n",
        "    df_resumo_cidade['quantidade_voos_atrasados'] / df_resumo_cidade['quantidade_voos_agendados']\n",
        ")\n",
        "\n",
        "df_resumo_cidade['prop_cancelados'] = (\n",
        "    df_resumo_cidade['quantidade_voos_cancelados'] / df_resumo_cidade['quantidade_voos_agendados']\n",
        ")\n",
        "\n",
        "df_resumo_cidade = df_resumo_cidade.sort_values(\n",
        "    by='quantidade_voos_agendados', ascending=False\n",
        ")\n",
        "\n",
        "df_resumo_cidade['prop_atrasados'] = df_resumo_cidade['prop_atrasados'].map('{:.2%}'.format)\n",
        "df_resumo_cidade['prop_cancelados'] = df_resumo_cidade['prop_cancelados'].map('{:.2%}'.format)\n",
        "\n",
        "print(f\"Novo Dataframe criado com sucesso! Abaixo as top 15 cidades por volume de voos agendados\")\n",
        "display(df_resumo_cidade.head(15))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbdadf09",
      "metadata": {
        "id": "cbdadf09"
      },
      "source": [
        "### Inferencias iniciais ###\n",
        "\n",
        "- O Dataset refere-se ao hist√≥rico de voos de 2024, por√©m s√≥ possui informa√ß√µes de v√¥os nos meses de Janeiro e Fevereiro (1 e 2);\n",
        "- As informa√ßoes nulas do dataset se concentram nas vari√°veis associadas a tempo.\n",
        "-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0065f40",
      "metadata": {
        "id": "d0065f40"
      },
      "outputs": [],
      "source": [
        "coluna_alvo = 'cancelled'\n",
        "\n",
        "df[coluna_alvo]=pd.to_numeric(df[coluna_alvo], errors='coerce').fillna(0).astype(int)\n",
        "\n",
        "# c) Prepara√ß√£o de Vari√°veis Num√©ricas (taxiamento)\n",
        "df['taxi_out'] = pd.to_numeric(df['taxi_out'], errors='coerce').fillna(0)\n",
        "\n",
        "# d) Cria√ß√£o de Features de Tempo (data)\n",
        "df['fl_date'] = pd.to_datetime(df['fl_date'], errors='coerce')\n",
        "df['day_of_year'] = df['fl_date'].dt.dayofyear\n",
        "df['week_of_year'] = df['fl_date'].dt.isocalendar().week.astype(int)\n",
        "\n",
        "# e) Codifica√ß√£o de Vari√°veis Categ√≥ricas (One-Hot Encoding)\n",
        "colunas_para_dummies = ['origin', 'origin_state_nm']\n",
        "df_para_regressao_logistica = pd.get_dummies(df, columns=colunas_para_dummies, drop_first=True)\n",
        "\n",
        "# f) Remo√ß√£o de colunas que n√£o podem ser Features\n",
        "colunas_para_remover = [\n",
        "        'fl_date',\n",
        "        'origin_city_name',\n",
        "        'flight_id' # NUNCA use IDs como features preditoras!\n",
        "    ]\n",
        "df_para_regressao_logistica.drop(columns=colunas_para_remover, inplace=True, errors='ignore')\n",
        "\n",
        "# 2. Defini√ß√£o de X e Y\n",
        "\n",
        "Y = df_para_regressao_logistica[coluna_alvo]\n",
        "X = df_para_regressao_logistica.drop(columns=[coluna_alvo])\n",
        "\n",
        "# Tratamento final de X: Remover colunas com NaN ou Infinitos\n",
        "X = X.replace([np.inf, -np.inf], np.nan).dropna(axis=1)\n",
        "\n",
        "print(f\"Dataset pronto. X: {X.shape[0]} linhas, {X.shape[1]} features.\")\n",
        "\n",
        "# 3. Divis√£o Treino e Teste (usando stratify para manter a propor√ß√£o de cancelamentos)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=1, stratify=Y)\n",
        "\n",
        "print(\"\\n--- Treinando Modelo de Regress√£o Log√≠stica ---\")\n",
        "\n",
        "# 4. Treinamento do Modelo\n",
        "model = LogisticRegression(solver='liblinear', random_state=1, max_iter=1000)\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "# 5. Previs√£o e Avalia√ß√£o\n",
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"\\n=======================================================\")\n",
        "print(\"‚úÖ RESULTADOS DA REGRESS√ÉO LOG√çSTICA (PREVIS√ÉO DE CANCELAMENTO)\")\n",
        "print(\"=======================================================\")\n",
        "\n",
        "# M√©tricas de Desempenho\n",
        "print(f\"Acur√°cia: {accuracy_score(Y_test, Y_pred):.4f}\")\n",
        "print(\"\\nRelat√≥rio de Classifica√ß√£o (Precision, Recall, F1-Score):\")\n",
        "# zero_division=0 evita o warning se uma classe n√£o for prevista\n",
        "print(classification_report(Y_test, Y_pred, zero_division=0))\n",
        "print(\"\\nMatriz de Confus√£o (real vs. previsto):\")\n",
        "\n",
        "cm = confusion_matrix(Y_test, Y_pred)\n",
        "\n",
        "# 2. Configura√ß√£o da Visualiza√ß√£o\n",
        "plt.figure(figsize=(6, 5))\n",
        "\n",
        "# Criar o Heatmap (Mapa de Calor)\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,              # Mostrar os n√∫meros dentro dos quadrados\n",
        "    fmt='d',                 # Formatar os n√∫meros como inteiros\n",
        "    cmap='Blues',            # Escolher um esquema de cores (Azul √© um bom padr√£o)\n",
        "    linewidths=0.5,          # Linhas entre os quadrados\n",
        "    linecolor='black',\n",
        "    cbar=False               # N√£o mostrar a barra de cores lateral\n",
        ")\n",
        "\n",
        "# 3. Adicionar R√≥tulos e T√≠tulos\n",
        "# Os r√≥tulos 0 e 1 correspondem a 'N√£o Cancelado' e 'Cancelado'\n",
        "class_names = ['N√£o Cancelado (0)', 'Cancelado (1)']\n",
        "plt.xticks(np.arange(len(class_names)) + 0.5, class_names, rotation=45, ha='right')\n",
        "plt.yticks(np.arange(len(class_names)) + 0.5, class_names, rotation=0)\n",
        "\n",
        "plt.title('Matriz de Confus√£o (Previs√£o de Cancelamento)', fontsize=14)\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n*Lembre-se: Para a Classe 1 (Cancelados), o Recall √© geralmente a m√©trica mais importante!*\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Divis√£o Treino e Teste (usando 70/30 e random_state para consist√™ncia)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=1, stratify=Y)\n",
        "\n",
        "print(\"\\n--- Treinando Modelo de √Årvore de Decis√£o ---\")\n",
        "\n",
        "    # 4. Treinamento do Modelo (Par√¢metros iniciais: max_depth limita o crescimento da √°rvore)\n",
        "model_tree = DecisionTreeClassifier(\n",
        "        max_depth=5,        # Limita a profundidade para evitar Overfitting e facilitar a inspe√ß√£o\n",
        "        random_state=1,\n",
        "        class_weight='balanced' # Tenta melhorar o Recall da Classe 1 (Cancelado)\n",
        "    )\n",
        "model_tree.fit(X_train, Y_train)\n",
        "\n",
        "    # 5. Previs√£o e Avalia√ß√£o\n",
        "Y_pred_tree = model_tree.predict(X_test)\n",
        "\n",
        "print(\"\\n=======================================================\")\n",
        "print(\"‚úÖ RESULTADOS DA √ÅRVORE DE DECIS√ÉO (PREVIS√ÉO DE CANCELAMENTO)\")\n",
        "print(\"=======================================================\")\n",
        "\n",
        "    # M√©tricas de Desempenho\n",
        "print(f\"Acur√°cia: {accuracy_score(Y_test, Y_pred_tree):.4f}\")\n",
        "print(\"\\nRelat√≥rio de Classifica√ß√£o (Precision, Recall, F1-Score):\")\n",
        "print(classification_report(Y_test, Y_pred_tree, zero_division=0))\n",
        "print(\"\\nMatriz de Confus√£o (real vs. previsto):\")\n",
        "\n",
        "cm_tree = confusion_matrix(Y_test, Y_pred_tree)\n",
        "# 2. Configura√ß√£o da Visualiza√ß√£o\n",
        "plt.figure(figsize=(6, 5))\n",
        "\n",
        "# Criar o Heatmap (Mapa de Calor)\n",
        "sns.heatmap(\n",
        "    cm_tree,\n",
        "    annot=True,              # Mostrar os n√∫meros dentro dos quadrados\n",
        "    fmt='d',                 # Formatar os n√∫meros como inteiros\n",
        "    cmap='Greens',           # Usando Verde para diferenciar da Log√≠stica\n",
        "    linewidths=0.5,\n",
        "    linecolor='black',\n",
        "    cbar=False\n",
        ")\n",
        "\n",
        "# 3. Adicionar R√≥tulos e T√≠tulos\n",
        "class_names = ['N√£o Cancelado (0)', 'Cancelado (1)']\n",
        "plt.xticks(np.arange(len(class_names)) + 0.5, class_names, rotation=45, ha='right')\n",
        "plt.yticks(np.arange(len(class_names)) + 0.5, class_names, rotation=0)\n",
        "\n",
        "plt.title('Matriz de Confus√£o - √Årvore de Decis√£o', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüö® Compare o canto Inferior Esquerdo (Falsos Negativos) com o modelo Log√≠stico.\")\n",
        "print(\"O modelo com o menor n√∫mero nessa c√©lula √© o melhor para a seguran√ßa operacional!\")"
      ],
      "metadata": {
        "id": "2MckA7kHtn85"
      },
      "id": "2MckA7kHtn85",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}